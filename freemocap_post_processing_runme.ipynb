{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rich.progress import track\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_freemocap_data(freemocap_marker_data:np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Takes in a 3d skeleton numpy array from freemocap and interpolates missing NaN values\"\"\"\n",
    "    num_frames = freemocap_marker_data.shape[0]\n",
    "    num_markers = freemocap_marker_data.shape[1]\n",
    "\n",
    "    freemocap_interpolated_data = np.empty((num_frames, num_markers, 3))\n",
    "\n",
    "    for marker in track(range(num_markers), description= 'Interpolating Data'):\n",
    "        this_marker_skel3d_data = freemocap_marker_data[:,marker,:]\n",
    "        df = pd.DataFrame(this_marker_skel3d_data)\n",
    "        df2 = df.interpolate(method = 'linear',axis = 0) #use pandas interpolation methods to fill in missing data\n",
    "        this_marker_interpolated_skel3d_array = np.array(df2)\n",
    "        #replace the remaining NaN values (the ones that often happen at the start of the recording)\n",
    "        this_marker_interpolated_skel3d_array = np.where(np.isfinite(this_marker_interpolated_skel3d_array), this_marker_interpolated_skel3d_array, np.nanmean(this_marker_interpolated_skel3d_array))\n",
    "        \n",
    "        freemocap_interpolated_data[:,marker,:] = this_marker_interpolated_skel3d_array\n",
    "        \n",
    "    return freemocap_interpolated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data, cutoff, sampling_rate, order):\n",
    "    \"\"\" Run a low pass butterworth filter on a single column of data\"\"\"\n",
    "    nyquist_freq = 0.5*sampling_rate\n",
    "    normal_cutoff = cutoff / nyquist_freq\n",
    "    # Get the filter coefficients \n",
    "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def filter_skeleton(skeleton_3d_data, cutoff, sampling_rate, order):\n",
    "    \"\"\" Take in a 3d skeleton numpy array and run a low pass butterworth filter on each marker in the data\"\"\"\n",
    "    num_frames = skeleton_3d_data.shape[0]\n",
    "    num_markers = skeleton_3d_data.shape[1]\n",
    "    filtered_data = np.empty((num_frames,num_markers,3))\n",
    "\n",
    "    for marker in range(num_markers):\n",
    "        for x in range(3):\n",
    "            filtered_data[:,marker,x] = butter_lowpass_filter(skeleton_3d_data[:,marker,x],cutoff,sampling_rate,order)\n",
    "\n",
    "    \n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_velocity_values_within_limit(skeleton_velocity_data, velocity_limit):\n",
    "    \"\"\"\n",
    "    This function takes in a skeleton velocity data array and a limit and returns the indices of the values that are within the limit\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for i in range(len(skeleton_velocity_data)):\n",
    "        if abs(skeleton_velocity_data[i]) <= velocity_limit:\n",
    "            indices.append(i+1) #add 1 to account for the difference in indices between the position and velocity data\n",
    "    return indices\n",
    "\n",
    "def find_matching_indices_in_lists(list_1,list_2,list_3,list_4):\n",
    "    \"\"\"\n",
    "    This function takes in four lists and returns the indices of the values that are in all four lists\n",
    "    \"\"\"\n",
    "    matching_values = [x for x in list_1 if x in list_2 and x in list_3 and x in list_4]\n",
    "\n",
    "    return matching_values\n",
    "def find_best_velocity_guess(skeleton_velocity_data, skeleton_indices, velocity_guess, iteration_range):\n",
    "    \"\"\"\n",
    "    This function iterates over velocity data and tries to pare down to a single frame that has the closest velocity to 0 for all foot markers\n",
    "    \"\"\"\n",
    "\n",
    "    right_heel_index = skeleton_indices.index('right_heel')\n",
    "    right_toe_index = skeleton_indices.index('right_foot_index')\n",
    "    left_heel_index = skeleton_indices.index('left_heel')\n",
    "    left_toe_index = skeleton_indices.index('left_foot_index')\n",
    "\n",
    "    skeleton_data_velocity_x_right_heel = skeleton_velocity_data[:,right_heel_index,0]\n",
    "    skeleton_data_velocity_x_right_toe = skeleton_velocity_data[:,right_toe_index,0]\n",
    "    skeleton_data_velocity_x_left_heel = skeleton_velocity_data[:,left_heel_index,0]\n",
    "    skeleton_data_velocity_x_left_toe = skeleton_velocity_data[:,left_toe_index,0]\n",
    "\n",
    "    #get a list of the frames where the velocity for that marker is within the velocity limit \n",
    "    right_heel_x_velocity_limits = find_velocity_values_within_limit(skeleton_data_velocity_x_right_heel, velocity_guess)\n",
    "    right_toe_x_velocity_limits = find_velocity_values_within_limit(skeleton_data_velocity_x_right_toe, velocity_guess)\n",
    "    left_heel_x_velocity_limits = find_velocity_values_within_limit(skeleton_data_velocity_x_left_heel, velocity_guess)\n",
    "    left_toe_x_velocity_limits = find_velocity_values_within_limit(skeleton_data_velocity_x_left_toe, velocity_guess)\n",
    "\n",
    "    #return a list of matching frame indices from the four lists generated above \n",
    "    matching_values = find_matching_indices_in_lists(right_heel_x_velocity_limits, right_toe_x_velocity_limits, left_heel_x_velocity_limits, left_toe_x_velocity_limits)\n",
    "    matching_values = [x for x in matching_values if x>75]\n",
    "    \n",
    "    #print(matching_values)\n",
    "    if len(matching_values) > 1 and velocity_guess > 0:\n",
    "        #if there are multiple matching values, decrease the guess a little bit and run the function again\n",
    "        #  \n",
    "        velocity_guess = velocity_guess - iteration_range\n",
    "        print('Current Velocity Guess:',velocity_guess, '| Number of Possible Frames:', len(matching_values), '| Possible Frames:', matching_values)\n",
    "        matching_values, velocity_guess = find_best_velocity_guess(skeleton_velocity_data, skeleton_indices, velocity_guess, iteration_range)\n",
    "\n",
    "        f = 2\n",
    "    elif len(matching_values) == 0:\n",
    "        #if there are no matching values (we decreased our guess too far), reset the guess to be a bit smaller and run the function again with smaller intervals between the guesses\n",
    "        iteration_range = iteration_range/2\n",
    "        matching_values, velocity_guess = find_best_velocity_guess(skeleton_velocity_data, skeleton_indices, velocity_guess + iteration_range*2, iteration_range)\n",
    "\n",
    "        f = 2\n",
    "    elif len(matching_values) == 1:\n",
    "        print('Good Frame:', matching_values,'| Final Velocity Guess:',velocity_guess)\n",
    "\n",
    "    return matching_values, velocity_guess\n",
    "\n",
    "\n",
    "def find_good_frame(skeleton_data, skeleton_indices:list, initial_velocity_guess:float, debug = False):\n",
    "    \"\"\"\n",
    "    Finds a frame (called the good frame) where the velocity of both feet are closest to 0\n",
    "\n",
    "    Input: \n",
    "        skeleton data: a 3D numpy array of skeleton data in freemocap format\n",
    "        skeleton indices: a list of joints being tracked by mediapipe/your 2d pose estimator\n",
    "        initial velocity guess: just a starting guess for the optimizer. Can adjust if you're not getting the results you want\n",
    "        debug: plots and displays the calculated good frame if True \n",
    "    \"\"\"\n",
    "\n",
    "    skeleton_velocity_data = np.diff(skeleton_data, axis=0)\n",
    "    \n",
    "    matching_values, velocity_guess = find_best_velocity_guess(skeleton_velocity_data, skeleton_indices, initial_velocity_guess, iteration_range=.1)\n",
    "\n",
    "    good_frame = matching_values[0]\n",
    "\n",
    "    return good_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_vector(point1,point2): \n",
    "    \"\"\"Put two points in, make a vector\"\"\"\n",
    "    vector = point2 - point1\n",
    "    return vector\n",
    "\n",
    "def calculate_unit_vector(vector): \n",
    "    \"\"\"Take in a vector, make it a unit vector\"\"\"\n",
    "    unit_vector = vector/np.linalg.norm(vector)\n",
    "    return unit_vector\n",
    "\n",
    "def calculate_shoulder_center_XYZ_coordinates(single_frame_skeleton_data,left_shoulder_index,right_shoulder_index ):\n",
    "    \"\"\"Take in the left and right shoulder indices, and calculate the shoulder center point\"\"\"\n",
    "    left_shoulder_point = single_frame_skeleton_data[left_shoulder_index,:]\n",
    "    right_shoulder_point = single_frame_skeleton_data[right_shoulder_index,:]\n",
    "    shoulder_center_XYZ_coordinates = (left_shoulder_point + right_shoulder_point)/2\n",
    "    \n",
    "    return shoulder_center_XYZ_coordinates\n",
    "\n",
    "\n",
    "def calculate_mid_hip_XYZ_coordinates(single_frame_skeleton_data,left_hip_index,right_hip_index):\n",
    "    \"\"\"Take in the left and right hip indices, and calculate the mid hip point\"\"\"\n",
    "    left_hip_point = single_frame_skeleton_data[left_hip_index,:]\n",
    "    right_hip_point = single_frame_skeleton_data[right_hip_index,:]\n",
    "    mid_hip_XYZ_coordinates = (left_hip_point + right_hip_point)/2\n",
    "\n",
    "    return mid_hip_XYZ_coordinates\n",
    "\n",
    "def calculate_mid_foot_XYZ_coordinate(single_frame_skeleton_data,left_heel_index,right_heel_index,):\n",
    "    \"\"\"Take in the primary and secondary foot indices, and calculate the mid foot point\"\"\"\n",
    "    right_foot_point = single_frame_skeleton_data[right_heel_index,:]\n",
    "    left_foot_point = single_frame_skeleton_data[left_heel_index,:]\n",
    "    mid_foot_XYZ_coordinates = (right_foot_point + left_foot_point)/2\n",
    "\n",
    "    return mid_foot_XYZ_coordinates\n",
    "\n",
    "# def calculate_translation_distance(skeleton_point_coordinate):\n",
    "#     \"\"\"Take a skeleton point coordinate and calculate its distance to the origin\"\"\"\n",
    "\n",
    "#     translation_distance = skeleton_point_coordinate - [0,0,0]\n",
    "#     return translation_distance \n",
    "\n",
    "\n",
    "def translate_skeleton_frame(rotated_skeleton_data_frame, translation_distance):\n",
    "    \"\"\"Take in a frame of rotated skeleton data, and apply the translation distance to each point in the skeleton\"\"\"\n",
    "\n",
    "    translated_skeleton_frame = rotated_skeleton_data_frame - translation_distance\n",
    "    return translated_skeleton_frame\n",
    "\n",
    "def translate_skeleton_to_origin(point_to_translate, original_skeleton_data):\n",
    "    num_frames = original_skeleton_data.shape[0]\n",
    "\n",
    "    translated_skeleton_data = np.zeros(original_skeleton_data.shape)\n",
    "\n",
    "    for frame in track (range(num_frames), description = 'Translating Skeleton'):\n",
    "        translated_skeleton_data[frame,:,:] = translate_skeleton_frame(original_skeleton_data[frame,:,:],point_to_translate)\n",
    "\n",
    "    return translated_skeleton_data\n",
    "\n",
    "def calculate_skewed_symmetric_cross_product(cross_product_vector):\n",
    "    #needed in the calculate_rotation_matrix function \n",
    "    skew_symmetric_cross_product = np.array([[0, -cross_product_vector[2], cross_product_vector[1]],\n",
    "                                             [cross_product_vector[2], 0, -cross_product_vector[0]],\n",
    "                                             [-cross_product_vector[1], cross_product_vector[0], 0]])\n",
    "    return skew_symmetric_cross_product\n",
    "\n",
    "\n",
    "def calculate_rotation_matrix(vector1,vector2):\n",
    "    \"\"\"Put in two vectors to calculate the rotation matrix between those two vectors\"\"\"\n",
    "    #based on the code found here: https://math.stackexchange.com/questions/180418/calculate-rotation-matrix-to-align-vector-a-to-vector-b-in-3d\"\"\"\n",
    "    \n",
    "    identity_matrix = np.identity(3)\n",
    "    vector_cross_product = np.cross(vector1,vector2)\n",
    "    vector_dot_product = np.dot(vector1,vector2)\n",
    "    skew_symmetric_cross_product = calculate_skewed_symmetric_cross_product(vector_cross_product)\n",
    "    rotation_matrix  = identity_matrix + skew_symmetric_cross_product + (np.dot(skew_symmetric_cross_product,skew_symmetric_cross_product))*(1 - vector_dot_product)/(np.linalg.norm(vector_cross_product)**2)\n",
    "\n",
    "    return rotation_matrix\n",
    "\n",
    "def rotate_point(point,rotation_matrix):\n",
    "    rotated_point = np.dot(rotation_matrix,point)\n",
    "    return rotated_point\n",
    "\n",
    "def rotate_skeleton_frame(this_frame_aligned_skeleton_data, rotation_matrix):\n",
    "    \"\"\"Take in a frame of skeleton data, and apply the rotation matrix to each point in the skeleton\"\"\"\n",
    "\n",
    "    this_frame_rotated_skeleton = np.zeros(this_frame_aligned_skeleton_data.shape)  #initialize the array to hold the rotated skeleton data for this frame\n",
    "    num_tracked_points = this_frame_aligned_skeleton_data.shape[0]\n",
    "\n",
    "    for i in range(num_tracked_points):\n",
    "        this_frame_rotated_skeleton[i,:] = rotate_point(this_frame_aligned_skeleton_data[i,:],rotation_matrix)\n",
    "\n",
    "    return this_frame_rotated_skeleton\n",
    "\n",
    "def rotate_skeleton_to_vector(reference_vector:np.ndarray, vector_to_rotate_to:np.ndarray, original_skeleton_np_array:np.ndarray) -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Find the rotation matrix needed to rotate the 'reference vector' to match the 'vector_to_rotate_to', and \n",
    "    rotate the entire skeleton with that matrix.\n",
    "\n",
    "        Input: \n",
    "            Reference Vector: The vector on the skeleton that you want to rotate/base the rotation matrix on \n",
    "            Vector_to_rotate_to: The vector that you want to align the skeleton too (i.e. the x-axis/y-axis etc.)\n",
    "            Original skeleton data: The freemocap data you want to rotate\n",
    "        Output:\n",
    "            rotated_skeleton_data: A numpy data array of your rotated skeleton\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    num_frames = original_skeleton_np_array.shape[0]\n",
    "    reference_unit_vector = calculate_unit_vector(reference_vector)\n",
    "    rotation_matrix = calculate_rotation_matrix(reference_unit_vector, vector_to_rotate_to)\n",
    "\n",
    "    rotated_skeleton_data_array = np.zeros(original_skeleton_np_array.shape)\n",
    "    for frame in track(range(num_frames), description = 'Rotating Skeleton'):\n",
    "        rotated_skeleton_data_array [frame,:,:] = rotate_skeleton_frame(original_skeleton_np_array[frame,:,:],rotation_matrix)\n",
    "\n",
    "    return rotated_skeleton_data_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def align_skeleton_with_origin(skeleton_data:np.ndarray, skeleton_indices:list, good_frame:int) -> np.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "    Takes in freemocap skeleton data and translates the skeleton to the origin, and then rotates the data \n",
    "    so that the skeleton is facing the +y direction and standing in the +z direction\n",
    "\n",
    "    Input:\n",
    "        skeleton data: a 3D numpy array of skeleton data in freemocap format\n",
    "        skeleton indices: a list of joints being tracked by mediapipe/your 2d pose estimator\n",
    "        good frame: the frame that you want to base the rotation on (can be entered manually, \n",
    "                    or use the 'good_frame_finder.py' to calculate it)\n",
    "        debug: If 'True', display a plot of the raw data and the 3 main alignment stages\n",
    "\n",
    "    Output:\n",
    "        spine aligned skeleton data: a 3d numpy array of the origin aligned data in freemocap format \n",
    "    \"\"\"\n",
    "    left_shoulder_index = skeleton_indices.index('left_shoulder')\n",
    "    right_shoulder_index = skeleton_indices.index('right_shoulder')\n",
    "\n",
    "    left_hip_index = skeleton_indices.index('left_hip')\n",
    "    right_hip_index = skeleton_indices.index('right_hip')\n",
    "\n",
    "    left_heel_index = skeleton_indices.index('left_heel')\n",
    "    right_heel_index = skeleton_indices.index('right_heel')\n",
    "    \n",
    "    origin = np.array([0, 0, 0])\n",
    "    x_axis = np.array([1, 0, 0])\n",
    "    y_axis = np.array([0, 1, 0])\n",
    "    z_axis = np.array([0, 0, 1])\n",
    "\n",
    "    x_vector = create_vector(origin,x_axis)\n",
    "    y_vector = create_vector(origin,y_axis)\n",
    "    z_vector = create_vector(origin,z_axis)\n",
    "\n",
    "\n",
    "    ## Translate the data such that the midpoint between the two feet is at the origin \n",
    "    hip_translated_mid_foot_XYZ = calculate_mid_foot_XYZ_coordinate(skeleton_data[good_frame,:,:],left_heel_index, right_heel_index)\n",
    "    foot_translated_skeleton_data = translate_skeleton_to_origin(hip_translated_mid_foot_XYZ,skeleton_data)\n",
    "\n",
    "    # Rotate the skeleton to face the +y direction\n",
    "    heel_vector_origin = foot_translated_skeleton_data[good_frame,right_heel_index,:]\n",
    "    heel_vector = create_vector(heel_vector_origin ,foot_translated_skeleton_data[good_frame,left_heel_index,:])\n",
    "\n",
    "\n",
    "    y_aligned_skeleton_data = rotate_skeleton_to_vector(heel_vector,-1*x_vector,foot_translated_skeleton_data)\n",
    "\n",
    "    #Rotating the skeleton so that the spine is aligned with +z\n",
    "    y_aligned_mid_hip_XYZ = calculate_mid_hip_XYZ_coordinates(y_aligned_skeleton_data[good_frame,:,:],left_hip_index,right_hip_index)\n",
    "    y_aligned_mid_shoulder_XYZ = calculate_shoulder_center_XYZ_coordinates(y_aligned_skeleton_data[good_frame,:,:], left_shoulder_index, right_shoulder_index)\n",
    "    y_aligned_spine_vector = create_vector(y_aligned_mid_hip_XYZ,y_aligned_mid_shoulder_XYZ)\n",
    "    \n",
    "    spine_aligned_skeleton_data = rotate_skeleton_to_vector(y_aligned_spine_vector,z_vector,y_aligned_skeleton_data)\n",
    "\n",
    "    return spine_aligned_skeleton_data, y_aligned_skeleton_data, foot_translated_skeleton_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediapipe_indices = [\n",
    "    'nose',\n",
    "    'left_eye_inner',\n",
    "    'left_eye',\n",
    "    'left_eye_outer',\n",
    "    'right_eye_inner',\n",
    "    'right_eye',\n",
    "    'right_eye_outer',\n",
    "    'left_ear',\n",
    "    'right_ear',\n",
    "    'mouth_left',\n",
    "    'mouth_right',\n",
    "    'left_shoulder',\n",
    "    'right_shoulder',\n",
    "    'left_elbow',\n",
    "    'right_elbow',\n",
    "    'left_wrist',\n",
    "    'right_wrist',\n",
    "    'left_pinky',\n",
    "    'right_pinky',\n",
    "    'left_index',\n",
    "    'right_index',\n",
    "    'left_thumb',\n",
    "    'right_thumb',\n",
    "    'left_hip',\n",
    "    'right_hip',\n",
    "    'left_knee',\n",
    "    'right_knee',\n",
    "    'left_ankle',\n",
    "    'right_ankle',\n",
    "    'left_heel',\n",
    "    'right_heel',\n",
    "    'left_foot_index',\n",
    "    'right_foot_index'\n",
    "    ]\n",
    "    \n",
    "def slice_mediapipe_data(mediapipe_full_skeleton_data, num_pose_joints):\n",
    "    pose_joint_range = range(num_pose_joints)\n",
    "\n",
    "    mediapipe_pose_data = mediapipe_full_skeleton_data[:,0:num_pose_joints,:] #load just the pose joints into a data array, removing hands and face data \n",
    "\n",
    "    return mediapipe_pose_data\n",
    "\n",
    "\n",
    "def return_indices_of_joints(list_of_indices, list_of_joint_names):\n",
    "\n",
    "    indices = []\n",
    "    for name in list_of_joint_names:\n",
    "        this_name_index = list_of_indices.index(name)\n",
    "        indices.append(this_name_index)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "def return_XYZ_coordinates_of_markers(freemocap_data, indices_list,frame):\n",
    "\n",
    "        XYZ_coordinates = []\n",
    "        for index in indices_list:\n",
    "            this_joint_coordinate = freemocap_data[frame,index,:]\n",
    "            XYZ_coordinates.append(this_joint_coordinate)\n",
    "\n",
    "        return XYZ_coordinates\n",
    "\n",
    "    \n",
    "def build_virtual_trunk_marker(freemocap_data,list_of_indices, trunk_joint_connection,frame):\n",
    "        trunk_marker_indices = return_indices_of_joints(list_of_indices, trunk_joint_connection)\n",
    "\n",
    "        trunk_XYZ_coordinates = return_XYZ_coordinates_of_markers(freemocap_data,trunk_marker_indices,frame)\n",
    "\n",
    "        trunk_proximal = (trunk_XYZ_coordinates[0] + trunk_XYZ_coordinates[1])/2\n",
    "        trunk_distal = (trunk_XYZ_coordinates[2] + trunk_XYZ_coordinates[3])/2\n",
    "\n",
    "        return trunk_proximal, trunk_distal\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "def build_mediapipe_skeleton(mediapipe_pose_data,segment_dataframe, mediapipe_indices) -> list:\n",
    "    \"\"\" This function takes in the mediapipe pose data array and the segment_conn_len_perc_dataframe. \n",
    "        For each frame of data, it loops through each segment we want to find and identifies the names\n",
    "        of the proximal and distal joints of that segment. Then it searches the mediapipe_indices list\n",
    "        to find the index that corresponds to the name of that segment. We plug the index into the \n",
    "        mediapipe_pose_data array to find the proximal/distal joints' XYZ coordinates at that frame. \n",
    "        The segment, its proximal joint and its distal joint gets thrown into a dictionary. \n",
    "        And then that dictionary gets saved to a list for each frame. By the end of the function, you \n",
    "        have a list that contains the skeleton segment XYZ coordinates for each frame.\"\"\"\n",
    "\n",
    "\n",
    "    num_frames = mediapipe_pose_data.shape[0]\n",
    "    num_frame_range = range(num_frames)\n",
    "\n",
    "    mediapipe_frame_segment_joint_XYZ = [] #empty list to hold all the skeleton XYZ coordinates/frame\n",
    "\n",
    "    \n",
    "    for frame in track(num_frame_range, description= 'Building a MediaPipe Skeleton'): \n",
    "\n",
    "        trunk_joint_connection = ['left_shoulder', 'right_shoulder', 'left_hip', 'right_hip']\n",
    "        trunk_virtual_markers = build_virtual_trunk_marker(mediapipe_pose_data, mediapipe_indices, trunk_joint_connection,frame)    \n",
    "\n",
    "        mediapipe_pose_skeleton_coordinates = {}\n",
    "        for segment,segment_info in segment_dataframe.iterrows(): #iterate through the data frame by the segment name and all the info for that segment\n",
    "            if segment == 'trunk':\n",
    "\n",
    "                #based on index, excract coordinate data from fmc mediapipe data\n",
    "                mediapipe_pose_skeleton_coordinates[segment] = [trunk_virtual_markers[0], \n",
    "                                                                trunk_virtual_markers[1]\n",
    "                                                                ]\n",
    "            elif segment == 'left_hand' or segment == 'right_hand':\n",
    "                proximal_joint_hand = segment_info['Joint_Connection'][0]\n",
    "                if segment == 'left_hand':\n",
    "                    distal_joint_hand = 'left_index'\n",
    "                else:\n",
    "                    distal_joint_hand = 'right_index'\n",
    "\n",
    "                proximal_joint_hand_index = mediapipe_indices.index(proximal_joint_hand)\n",
    "                distal_joint_hand_index = mediapipe_indices.index(distal_joint_hand)\n",
    "\n",
    "                mediapipe_pose_skeleton_coordinates[segment] = [mediapipe_pose_data[frame,proximal_joint_hand_index, :],\n",
    "                                                                mediapipe_pose_data[frame,distal_joint_hand_index,:]]\n",
    "\n",
    "            elif segment == 'left_foot' or segment == 'right_foot':\n",
    "                if segment == 'left_foot':\n",
    "                    proximal_joint_foot_name = 'left_ankle'\n",
    "                else:\n",
    "                    proximal_joint_foot_name = 'right_ankle'\n",
    "                \n",
    "                proximal_joint_foot_index = mediapipe_indices.index(proximal_joint_foot_name)\n",
    "\n",
    "                distal_joint_foot = segment_info['Joint_Connection'][1]\n",
    "                distal_joint_foot_index = mediapipe_indices.index(distal_joint_foot)\n",
    "                mediapipe_pose_skeleton_coordinates[segment] = [mediapipe_pose_data[frame,proximal_joint_foot_index, :],\n",
    "                                                                mediapipe_pose_data[frame, distal_joint_foot_index,:]]            \n",
    "\n",
    "            else:\n",
    "                proximal_joint_name = segment_info['Joint_Connection'][0] \n",
    "                distal_joint_name = segment_info['Joint_Connection'][1]\n",
    "\n",
    "            #get the mediapipe index for the proximal and distal joint for this segment\n",
    "                proximal_joint_index = mediapipe_indices.index(proximal_joint_name)\n",
    "                distal_joint_index = mediapipe_indices.index(distal_joint_name)\n",
    "\n",
    "            #use the mediapipe indices to get the XYZ coordinates for the prox/distal joints and throw it in a dictionary\n",
    "            #mediapipe_pose_skeleton_coordinates[segment] = {'proximal':mediapipe_pose_data[frame,proximal_joint_index,:],'distal':mediapipe_pose_data[frame,distal_joint_index,:]}\n",
    "                mediapipe_pose_skeleton_coordinates[segment] = [mediapipe_pose_data[frame,proximal_joint_index,:],mediapipe_pose_data[frame,distal_joint_index,:]]\n",
    "                \n",
    "        mediapipe_frame_segment_joint_XYZ.append(mediapipe_pose_skeleton_coordinates)\n",
    "        f = 2 \n",
    "    \n",
    "    return mediapipe_frame_segment_joint_XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values for segment weight and segment mass percentages taken from Winter anthropometry tables\n",
    "#https://imgur.com/a/aD74j\n",
    "#Winter, D.A. (2005) Biomechanics and Motor Control of Human Movement. 3rd Edition, John Wiley & Sons, Inc., Hoboken.\n",
    "\n",
    "\n",
    "\n",
    "segments = [\n",
    "'head',\n",
    "'trunk',\n",
    "'right_upper_arm',\n",
    "'left_upper_arm',\n",
    "'right_forearm',\n",
    "'left_forearm',\n",
    "'right_hand',\n",
    "'left_hand',\n",
    "'right_thigh',\n",
    "'left_thigh',\n",
    "'right_shin',\n",
    "'left_shin',\n",
    "'right_foot',\n",
    "'left_foot'\n",
    "]\n",
    "\n",
    "joint_connections = [\n",
    "['left_ear','right_ear'],\n",
    "['mid_chest_marker', 'mid_hip_marker'], \n",
    "['right_shoulder','right_elbow'],\n",
    "['left_shoulder','left_elbow'],\n",
    "['right_elbow', 'right_wrist'],\n",
    "['left_elbow', 'left_wrist'],\n",
    "['right_wrist', 'right_hand_marker'], \n",
    "['left_wrist', 'left_hand_marker'],\n",
    "['right_hip', 'right_knee'],\n",
    "['left_hip', 'left_knee'],\n",
    "['right_knee', 'right_ankle'],\n",
    "['left_knee', 'left_ankle'],\n",
    "['right_back_of_foot_marker', 'right_foot_index'], \n",
    "['left_back_of_foot_marker', 'left_foot_index']\n",
    "]\n",
    "\n",
    "segment_COM_lengths = [\n",
    ".5,\n",
    ".5,\n",
    ".436,\n",
    ".436,\n",
    ".430,\n",
    ".430,\n",
    ".506, \n",
    ".506, \n",
    ".433,\n",
    ".433,\n",
    ".433,\n",
    ".433,\n",
    ".5, \n",
    ".5  \n",
    "]\n",
    "\n",
    "segment_COM_percentages = [\n",
    ".081,\n",
    ".497,\n",
    ".028,\n",
    ".028,\n",
    ".016,\n",
    ".016,\n",
    ".006,\n",
    ".006,\n",
    ".1,\n",
    ".1,\n",
    ".0465,\n",
    ".0465,\n",
    ".0145,\n",
    ".0145\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_segment_COM(segment_conn_len_perc_dataframe,skelcoordinates_frame_segment_joint_XYZ, num_frame_range):\n",
    "    segment_COM_frame_dict = []\n",
    "    for frame in track(num_frame_range, description = 'Calculating Segment Center of Mass'):\n",
    "        segment_COM_dict = {}\n",
    "        for segment,segment_info in segment_conn_len_perc_dataframe.iterrows():\n",
    "            this_segment_XYZ = skelcoordinates_frame_segment_joint_XYZ[frame][segment]\n",
    "\n",
    "            #for mediapipe\n",
    "            this_segment_proximal = this_segment_XYZ[0]\n",
    "            this_segment_distal = this_segment_XYZ[1]\n",
    "            this_segment_COM_length = segment_info['Segment_COM_Length']\n",
    "\n",
    "            this_segment_COM = this_segment_proximal + this_segment_COM_length*(this_segment_distal-this_segment_proximal)\n",
    "            segment_COM_dict[segment] = this_segment_COM\n",
    "        segment_COM_frame_dict.append(segment_COM_dict)\n",
    "    return segment_COM_frame_dict\n",
    "\n",
    "\n",
    "def reformat_segment_COM(segment_COM_frame_dict, num_frame_range,num_segments):\n",
    "    \n",
    "    segment_COM_frame_imgPoint_XYZ = np.empty([int(len(num_frame_range)),int(num_segments),3])\n",
    "    for frame in num_frame_range:\n",
    "        this_frame_skeleton = segment_COM_frame_dict[frame]\n",
    "        for joint_count,segment in enumerate(this_frame_skeleton.keys()):\n",
    "            segment_COM_frame_imgPoint_XYZ[frame,joint_count,:] = this_frame_skeleton[segment]\n",
    "    return segment_COM_frame_imgPoint_XYZ\n",
    "\n",
    "\n",
    "\n",
    "def calculate_total_body_COM(segment_conn_len_perc_dataframe,segment_COM_frame_dict,num_frame_range):\n",
    "    totalBodyCOM_frame_XYZ = np.empty([int(len(num_frame_range)),3])\n",
    "\n",
    "    for frame in track(num_frame_range, description = 'Calculating Total Body Center of Mass'):\n",
    "\n",
    "        this_frame_total_body_percentages = []\n",
    "        this_frame_skeleton = segment_COM_frame_dict[frame]\n",
    "\n",
    "        for segment, segment_info in segment_conn_len_perc_dataframe.iterrows():\n",
    "\n",
    "            this_segment_COM = this_frame_skeleton[segment]\n",
    "            this_segment_COM_percentage = segment_info['Segment_COM_Percentage']\n",
    "\n",
    "            this_segment_total_body_percentage = this_segment_COM * this_segment_COM_percentage\n",
    "            this_frame_total_body_percentages.append(this_segment_total_body_percentage)\n",
    "\n",
    "        this_frame_total_body_COM = np.nansum(this_frame_total_body_percentages,axis = 0)\n",
    "       \n",
    "        totalBodyCOM_frame_XYZ[frame,:] = this_frame_total_body_COM\n",
    "\n",
    "    f=2\n",
    "    return totalBodyCOM_frame_XYZ \n",
    "\n",
    "def build_anthropometric_dataframe(segments:list,joint_connections:list,segment_COM_lengths:list,segment_COM_percentages:list) -> pd.DataFrame:\n",
    "    #load anthropometric data into a pandas dataframe\n",
    "    df = pd.DataFrame(list(zip(segments,joint_connections,segment_COM_lengths,segment_COM_percentages)),columns = ['Segment_Name','Joint_Connection','Segment_COM_Length','Segment_COM_Percentage'])\n",
    "    segment_conn_len_perc_dataframe = df.set_index('Segment_Name')\n",
    "    return segment_conn_len_perc_dataframe\n",
    "\n",
    "def run(freemocap_marker_data_array:np.ndarray, pose_estimation_skeleton:list, anthropometric_info_dataframe:pd.DataFrame):\n",
    "\n",
    "    num_frames = freemocap_marker_data_array.shape[0]\n",
    "    num_frame_range = range(num_frames)\n",
    "    num_segments = len(anthropometric_info_dataframe)\n",
    "\n",
    "    segment_COM_frame_dict = calculate_segment_COM(anthropometric_info_dataframe, pose_estimation_skeleton, num_frame_range)\n",
    "    segment_COM_frame_imgPoint_XYZ = reformat_segment_COM(segment_COM_frame_dict,num_frame_range, num_segments)\n",
    "    totalBodyCOM_frame_XYZ = calculate_total_body_COM(anthropometric_info_dataframe,segment_COM_frame_dict,num_frame_range)\n",
    "\n",
    "    return segment_COM_frame_dict,segment_COM_frame_imgPoint_XYZ,totalBodyCOM_frame_XYZ\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f364fe670db34369a25162be5dbeee74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\aaron\\AppData\\Local\\Temp\\ipykernel_35432\\623468142.py:14: RuntimeWarning: Mean of \n",
       "empty slice\n",
       "  this_marker_interpolated_skel3d_array = \n",
       "np.where(np.isfinite(this_marker_interpolated_skel3d_array), \n",
       "this_marker_interpolated_skel3d_array, np.nanmean(this_marker_interpolated_skel3d_array))\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\aaron\\AppData\\Local\\Temp\\ipykernel_35432\\623468142.py:14: RuntimeWarning: Mean of \n",
       "empty slice\n",
       "  this_marker_interpolated_skel3d_array = \n",
       "np.where(np.isfinite(this_marker_interpolated_skel3d_array), \n",
       "this_marker_interpolated_skel3d_array, np.nanmean(this_marker_interpolated_skel3d_array))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolating and Filtering Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c19cd110dec45719187611c763bb6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning Data with Origin\n",
      "Current Velocity Guess: 0.19999999999999998 | Number of Possible Frames: 13 | Possible Frames: [612, 917, 944, 950, 1114, 1148, 1158, 1159, 1160, 1161, 1169, 1170, 1185]\n",
      "Current Velocity Guess: 0.09999999999999998 | Number of Possible Frames: 5 | Possible Frames: [612, 917, 1159, 1160, 1170]\n",
      "Good Frame: [1170] | Final Velocity Guess: 0.09999999999999998\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a454b2d1744d1e8ccffc165e6c2721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023765002f154010abda86545d4a9e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4215e2de456d4d189079898073ffc21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating COM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4610246702c94e8d8224ada1276544a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfb702205254bc88049f73eee6432c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Set paths and load data\n",
    "freemocap_data_folder_path = Path(r\"D:\\ValidationStudy_numCams\\FreeMoCap_Data\")\n",
    "#sessionID = 'sesh_2022-05-24_15_55_40_JSM_T1_BOS' #name of the sessionID folder\n",
    "sessionID = 'sesh_2022-05-24_16_10_46_WalkRun_front_back'\n",
    "data_array_path = freemocap_data_folder_path/sessionID/'DataArrays'\n",
    "freemocap_marker_data_array = np.load(data_array_path/'mediaPipeSkel_3d.npy')\n",
    "\n",
    "\n",
    "print('Interpolating and Filtering Data')\n",
    "\n",
    "#Interpolate the data\n",
    "freemocap_interpolated_data = interpolate_freemocap_data(freemocap_marker_data_array)\n",
    "\n",
    "#Filter the data, set the filtering options here \n",
    "sampling_rate = 30\n",
    "cutoff = 10\n",
    "order = 4 \n",
    "freemocap_filtered_marker_data = filter_skeleton(freemocap_interpolated_data,cutoff, sampling_rate, order)\n",
    "np.save(data_array_path/'mediaPipeSkel_3d_filtered', freemocap_filtered_marker_data)\n",
    "\n",
    "#add the good frame finder\n",
    "\n",
    "\n",
    "#Align the data\n",
    "print('Aligning Data with Origin')\n",
    "good_frame = find_good_frame(freemocap_filtered_marker_data,mediapipe_indices,.3)\n",
    "freemocap_alignment_marker_data_tuple = align_skeleton_with_origin(freemocap_filtered_marker_data, mediapipe_indices, good_frame)\n",
    "origin_aligned_freemocap_marker_data = freemocap_alignment_marker_data_tuple[0]\n",
    "np.save(data_array_path/'mediaPipeSkel_3d_origin_aligned', origin_aligned_freemocap_marker_data) \n",
    "\n",
    "#Calculate segment and total body COM\n",
    "print('Calculating COM')\n",
    "anthropometric_info_dataframe = build_anthropometric_dataframe(segments,joint_connections,segment_COM_lengths,segment_COM_percentages)\n",
    "skelcoordinates_frame_segment_joint_XYZ = build_mediapipe_skeleton(origin_aligned_freemocap_marker_data,anthropometric_info_dataframe,mediapipe_indices)\n",
    "segment_COM_frame_dict,segment_COM_frame_imgPoint_XYZ,totalBodyCOM_frame_XYZ = run(origin_aligned_freemocap_marker_data,skelcoordinates_frame_segment_joint_XYZ, anthropometric_info_dataframe) \n",
    "\n",
    "np.save(data_array_path/'segmentedCOM_frame_joint_XYZ.npy', segment_COM_frame_imgPoint_XYZ)\n",
    "np.save(data_array_path/'totalBodyCOM_frame_XYZ.npy',totalBodyCOM_frame_XYZ)\n",
    "open_file = open(data_array_path/'mediapipe_skeleton_segments_dict.pkl', \"wb\")\n",
    "pickle.dump(skelcoordinates_frame_segment_joint_XYZ, open_file)\n",
    "open_file.close()\n",
    "#Save filtered data here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('validation_req_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cebf9e452051950f5db6f9bf61a22d959bf2fa37e24565cbafeb131ea8ea609e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
